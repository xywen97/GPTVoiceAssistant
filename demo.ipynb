{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始监听麦克风...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed7c3dc2ef540d7981170c7dfb5ce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feec4d16f6554dcbb20abe5b47c49da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d052b812c8ef490499f775131520a03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='重置', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'temp_1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 277\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir():\n\u001b[0;32m    276\u001b[0m     \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mtemp_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 277\u001b[0m         os\u001b[39m.\u001b[39;49mremove(file)\n\u001b[0;32m    279\u001b[0m counter_file \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    280\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'temp_1.wav'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "import websocket\n",
    "import hashlib\n",
    "import base64\n",
    "import hmac\n",
    "import json\n",
    "from urllib.parse import urlencode\n",
    "import ssl\n",
    "from wsgiref.handlers import format_date_time\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "import _thread as thread\n",
    "import numpy as np\n",
    "import openai\n",
    "import pyttsx3\n",
    "import ctypes\n",
    "import inspect\n",
    "import pygame\n",
    "\n",
    "# Settings\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 10\n",
    "WAVE_OUTPUT_FILENAME = \"tmp.pcm\"\n",
    "wsParam = None\n",
    "\n",
    "STATUS_FIRST_FRAME = 0\n",
    "STATUS_CONTINUE_FRAME = 1 \n",
    "STATUS_LAST_FRAME = 2\n",
    "my_saying = \"\"\n",
    "\n",
    "THRESHOLD = 500  # The threshold intensity that defines silence signal (lower than).\n",
    "frames = []\n",
    "messages = []\n",
    "silence_flag = False\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,input_device_index=1,\n",
    "                frames_per_buffer=CHUNK)\n",
    "speak_thread = None\n",
    "\n",
    "class Ws_Param(object):\n",
    "    # Initialize\n",
    "    def __init__(self, APPID, APIKey, APISecret, AudioFile):\n",
    "        self.APPID = APPID\n",
    "        self.APIKey = APIKey\n",
    "        self.APISecret = APISecret\n",
    "        self.AudioFile = AudioFile\n",
    "\n",
    "        self.CommonArgs = {\"app_id\": self.APPID}\n",
    "        self.BusinessArgs = {\"domain\": \"iat\", \"language\": \"zh_cn\", \"accent\": \"mandarin\", \"vinfo\":1,\"vad_eos\":10000}\n",
    "\n",
    "    # Generate url\n",
    "    def create_url(self):\n",
    "        url = 'wss://ws-api.xfyun.cn/v2/iat'\n",
    "        # Get current time\n",
    "        now = datetime.now()\n",
    "        date = format_date_time(mktime(now.timetuple()))\n",
    "\n",
    "        # concat string to generate signature origin string\n",
    "        signature_origin = \"host: \" + \"ws-api.xfyun.cn\" + \"\\n\"\n",
    "        signature_origin += \"date: \" + date + \"\\n\"\n",
    "        signature_origin += \"GET \" + \"/v2/iat \" + \"HTTP/1.1\"\n",
    "        # use hmac-sha256 encrypt, and encode as base64\n",
    "        signature_sha = hmac.new(self.APISecret.encode('utf-8'), signature_origin.encode('utf-8'),\n",
    "                                 digestmod=hashlib.sha256).digest()\n",
    "        signature_sha = base64.b64encode(signature_sha).decode(encoding='utf-8')\n",
    "\n",
    "        authorization_origin = \"api_key=\\\"%s\\\", algorithm=\\\"%s\\\", headers=\\\"%s\\\", signature=\\\"%s\\\"\" % (\n",
    "            self.APIKey, \"hmac-sha256\", \"host date request-line\", signature_sha)\n",
    "        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode(encoding='utf-8')\n",
    "        # make a dict\n",
    "        v = {\n",
    "            \"authorization\": authorization,\n",
    "            \"date\": date,\n",
    "            \"host\": \"ws-api.xfyun.cn\"\n",
    "        }\n",
    "        # put dict into url\n",
    "        url = url + '?' + urlencode(v)\n",
    "        return url\n",
    "\n",
    "\n",
    "# 收到websocket消息的处理\n",
    "def on_message(ws, message):\n",
    "    try:\n",
    "        code = json.loads(message)[\"code\"]\n",
    "        sid = json.loads(message)[\"sid\"]\n",
    "        if code != 0:\n",
    "            errMsg = json.loads(message)[\"message\"]\n",
    "            # print(\"sid:%s call error:%s code is:%s\" % (sid, errMsg, code))\n",
    "\n",
    "        else:\n",
    "            data = json.loads(message)[\"data\"][\"result\"][\"ws\"]\n",
    "            # print(data)\n",
    "            # print(json.loads(message))\n",
    "            result = \"\"\n",
    "            for i in data:\n",
    "                for w in i[\"cw\"]:\n",
    "                    result += w[\"w\"]\n",
    "            # print(\"sid:%s call success!,data is:%s\" % (sid, json.dumps(data, ensure_ascii=False)))\n",
    "            global my_saying\n",
    "            for i in data:\n",
    "                for w in i[\"cw\"]:\n",
    "                    my_saying += w[\"w\"]\n",
    "            # print(my_saying)\n",
    "    except Exception as e:\n",
    "        print(\"receive msg,but parse exception:\", e)\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(\"### error:\", error)\n",
    "\n",
    "def on_close(ws,a,b):\n",
    "    # print(\"### closed ###\")\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "# websocket handler\n",
    "def on_open(ws):\n",
    "    def run(*args):\n",
    "        global wsParam\n",
    "        frameSize = 8000  # size of each frame of audio data\n",
    "        intervel = 0.04  # interval between two frames of audio data\n",
    "        status = STATUS_FIRST_FRAME  # status of audio data, 0 for first frame, 1 for continue frame, 2 for last frame\n",
    "\n",
    "        with open(wsParam.AudioFile, \"rb\") as fp:\n",
    "            while True:\n",
    "                buf = fp.read(frameSize)\n",
    "                # end of file\n",
    "                if not buf:\n",
    "                    status = STATUS_LAST_FRAME\n",
    "                # handle the first frame\n",
    "                # send data to server, the format of data is json\n",
    "                # appid is needed here\n",
    "                if status == STATUS_FIRST_FRAME:\n",
    "\n",
    "                    d = {\"common\": wsParam.CommonArgs,\n",
    "                         \"business\": wsParam.BusinessArgs,\n",
    "                         \"data\": {\"status\": 0, \"format\": \"audio/L16;rate=16000\",\n",
    "                                  \"audio\": str(base64.b64encode(buf), 'utf-8'),\n",
    "                                  \"encoding\": \"raw\"}}\n",
    "                    d = json.dumps(d)\n",
    "                    ws.send(d)\n",
    "                    status = STATUS_CONTINUE_FRAME\n",
    "                # handle the continue frame\n",
    "                elif status == STATUS_CONTINUE_FRAME:\n",
    "                    d = {\"data\": {\"status\": 1, \"format\": \"audio/L16;rate=16000\",\n",
    "                                  \"audio\": str(base64.b64encode(buf), 'utf-8'),\n",
    "                                  \"encoding\": \"raw\"}}\n",
    "                    ws.send(json.dumps(d))\n",
    "                # handle the last frame\n",
    "                elif status == STATUS_LAST_FRAME:\n",
    "                    d = {\"data\": {\"status\": 2, \"format\": \"audio/L16;rate=16000\",\n",
    "                                  \"audio\": str(base64.b64encode(buf), 'utf-8'),\n",
    "                                  \"encoding\": \"raw\"}}\n",
    "                    ws.send(json.dumps(d))\n",
    "                    time.sleep(1)\n",
    "                    break\n",
    "                # interval between two frames of audio data\n",
    "                time.sleep(intervel)\n",
    "        ws.close()\n",
    "\n",
    "    thread.start_new_thread(run, ())\n",
    "\n",
    "# For recording, not used\n",
    "def record():\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,input_device_index=1,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    print(\"Start recording, please say something ...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished!\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def recognize():\n",
    "    global wsParam\n",
    "    # input your own params\n",
    "    # you can get these params in xfyun website/科大讯飞开放平台/语音听写\n",
    "    wsParam = Ws_Param(APPID='xxx', APISecret='xxx',\n",
    "                       APIKey='xxx',\n",
    "                       AudioFile=r'tmp.pcm')\n",
    "    websocket.enableTrace(False)\n",
    "    wsUrl = wsParam.create_url()\n",
    "    ws = websocket.WebSocketApp(wsUrl, on_message=on_message, on_error=on_error, on_close=on_close)\n",
    "    ws.on_open = on_open\n",
    "    ws.run_forever(sslopt={\"cert_reqs\": ssl.CERT_NONE})\n",
    "\n",
    "def gpt(messages):\n",
    "    openai.api_key = 'sk-xxxxxxxxxxxxxxxxxxxxxxxx'\n",
    "    global counter\n",
    "    # global messages\n",
    "    # messages.append({\"role\": \"user\", \"content\": message})\n",
    "    # print(message)\n",
    "\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=messages,\n",
    "        temperature = 1\n",
    "    )\n",
    "    reply = chat.choices[0].message.content\n",
    "\n",
    "    # messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    # time.sleep(5)\n",
    "    return reply\n",
    "\n",
    "text_box = widgets.Textarea()\n",
    "display(text_box)\n",
    "\n",
    "counter_box = widgets.Textarea()\n",
    "display(counter_box)\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "# # remove temp_*.wav files\n",
    "# for file in os.listdir():\n",
    "#     if file.startswith(\"temp_\") and file.endswith(\".wav\"):\n",
    "#         os.remove(file)\n",
    "\n",
    "counter_file = 0\n",
    "try:\n",
    "    while True:\n",
    "        # time.sleep(0.1)\n",
    "        data = stream.read(CHUNK)\n",
    "        audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "        energy = np.sum(np.abs(audio_data)) / CHUNK\n",
    "        frames.append(data)\n",
    "        counter_box.value = str(len(frames))\n",
    "        \n",
    "        # remove old frames every 1000 frames\n",
    "        if len(frames) > 1000:\n",
    "            frames = frames[-5:]\n",
    "        \n",
    "        if energy > THRESHOLD:\n",
    "            print(\"\\n ----------------- New chat -----------------\\n\")\n",
    "            pygame.mixer.music.stop()\n",
    "            # start recording\n",
    "            frames = frames[-5:]\n",
    "            time_silence = 0\n",
    "            while True:\n",
    "                data = stream.read(CHUNK)\n",
    "                audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "                energy = np.sum(np.abs(audio_data)) / CHUNK\n",
    "                \n",
    "                frames.append(data)\n",
    "                text_box.value = \"Recording ...\"\n",
    "                if energy < THRESHOLD:\n",
    "                    if not silence_flag:\n",
    "                        silence_flag = True\n",
    "                        time_silence = time.time()\n",
    "                    else:\n",
    "                        if time.time() - time_silence > 1:\n",
    "                            text_box.value = \"Stop recording, saving...\"\n",
    "                            wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "                            wf.setnchannels(CHANNELS)\n",
    "                            wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "                            wf.setframerate(RATE)\n",
    "                            wf.writeframes(b''.join(frames))\n",
    "                            wf.close()\n",
    "\n",
    "                            silence_flag = False\n",
    "                            frames = []\n",
    "\n",
    "                            break\n",
    "                        else:\n",
    "                            pass\n",
    "                else:\n",
    "                    silence_flag = False\n",
    "                    time_silence = 0\n",
    "            \n",
    "            # recognize\n",
    "            text_box.value = \"Recognizing ...\"\n",
    "            recognize()\n",
    "            if my_saying != \"\":\n",
    "                if counter_file >=5:\n",
    "                    counter_file = 0\n",
    "                counter_file += 1\n",
    "                print(f\"You: {my_saying}\")\n",
    "                messages.append({\"role\": \"user\", \"content\": my_saying})\n",
    "                reply = gpt(messages)\n",
    "                messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "                print(f\"Assit: {reply}\")\n",
    "\n",
    "                outfile = f\"temp_{counter_file}.wav\"\n",
    "                engine = pyttsx3.init()\n",
    "                engine.save_to_file(reply, outfile)\n",
    "                engine.runAndWait()\n",
    "                engine.stop()\n",
    "                # close the engine\n",
    "                pygame.mixer.music.load(outfile)\n",
    "                pygame.mixer.music.play()\n",
    "                        \n",
    "                # thread.start_new_thread(run, ())\n",
    "\n",
    "                my_saying = \"\"\n",
    "            else:\n",
    "                print(\"Can't recognize, please try again\")\n",
    "            \n",
    "        else:\n",
    "            text_box.value = \"No sound detected\"\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # if user hits Ctrl/C then exit and close the stream, pygame\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    pygame.mixer.music.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
